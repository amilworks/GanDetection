{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AmilGan Detection using Progressive Neural Architecture Search**\n",
    "#### Amil Khan | March 1, 2019 | Version 2\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from torch.autograd import Variable\n",
    "from functools import reduce\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import apex\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex.fp16_utils import *\n",
    "from apex import amp, optimizers\n",
    "# from apex.multi_tensor_apply import multi_tensor_applier\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading, Preprocessing, Wrangling, Cleansing\n",
    "\n",
    "I chose to functionalize everything in the data preprocessing pipeline for two reasons:\n",
    "\n",
    "- **Reproducibility**  Many times, there is a large body of beautiful code that has been written, but no documentation. The data processing step is usually where people get stuck.\n",
    "- **Iterability** I wanted to iterate fast when chnaging parameters in the module, as well as have one block of code that will take care of everything after restarting the kernal.\n",
    "\n",
    "**Inputs**: \n",
    "- `path_to_train`: Path to your training set folder (I am using PyTorch's `ImageFolder` module)\n",
    "- `path_to_test`: Path to your test set folder\n",
    "- `num_workers`: number of subprocesses to use for data loading\n",
    "- `batch_size`: how many samples per batch to load\n",
    "- `valid_size`: percentage of training set to use as validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DataConstructor2000(path_to_train, path_to_test, classes=None, num_workers=4, batch_size=32, valid_size = 0.2):\n",
    "    \n",
    "  \n",
    "    # Transformations to the image, edit as need be\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize([331,331]),\n",
    "        transforms.ToTensor()])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(path_to_train, transform=transform)\n",
    "    print(\"Successfully Loaded Training Set.\")\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(path_to_test, transform=transform)\n",
    "    print(\"Successfully Loaded Test Set.\")\n",
    "\n",
    "    \n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                               sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, \n",
    "        num_workers=num_workers, shuffle=True)\n",
    "    if classes != None:\n",
    "        print(\"Number of Classes:\", len(classes))\n",
    "    return train_loader, valid_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader,test_loader, classes = DataConstructor2000(path_to_train='/workspace/Documents/pretrained-models.pytorch-master/pretrainedmodels/training/',path_to_test='/workspace/Documents/pretrained-models.pytorch-master/pretrainedmodels/test/',\n",
    "                                                                       classes=['Fake','Real'],num_workers=40, batch_size=45, valid_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize for Confirmation\n",
    "You do not need to change anything here. It should run right out of the box. But feel free to change what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5  # unnormalize if you added normalization in the transformation step\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "print(images.shape)\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Define the Model\n",
    "\n",
    "So I am using `PNASNET` because, at least to my current research, it provides state of the art performance currently on a variety of popular datasets.\n",
    "\n",
    "__Abstract.__ We propose a new method for learning the structure of con-volutional  neural  networks  (CNNs)  that  is  more  efficient  than  recent state-of-the-art methods based on reinforcement learning and evolution-ary algorithms. Our approach uses a sequential model-based optimization(SMBO) strategy, in which we search for structures in order of increasing complexity, while simultaneously learning a surrogate model to guide thesearch through structure space. Direct comparison under the same searchspace shows that our method is up to 5 times more efficient than the RL method of Zoph et al. (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaxPool(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size, stride=1, padding=1, zero_pad=False):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0)) if zero_pad else None\n",
    "        self.pool = nn.MaxPool2d(kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.zero_pad:\n",
    "            x = self.zero_pad(x)\n",
    "        x = self.pool(x)\n",
    "        if self.zero_pad:\n",
    "            x = x[:, :, 1:, 1:]\n",
    "        return x\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dw_kernel_size, dw_stride,\n",
    "                 dw_padding):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels,\n",
    "                                          kernel_size=dw_kernel_size,\n",
    "                                          stride=dw_stride, padding=dw_padding,\n",
    "                                          groups=in_channels, bias=False)\n",
    "        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv2d(x)\n",
    "        x = self.pointwise_conv2d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparables(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 stem_cell=False, zero_pad=False):\n",
    "        super(BranchSeparables, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        middle_channels = out_channels if stem_cell else in_channels\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0)) if zero_pad else None\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, middle_channels,\n",
    "                                           kernel_size, dw_stride=stride,\n",
    "                                           dw_padding=padding)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(middle_channels, eps=0.001)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(middle_channels, out_channels,\n",
    "                                           kernel_size, dw_stride=1,\n",
    "                                           dw_padding=padding)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu_1(x)\n",
    "        if self.zero_pad:\n",
    "            x = self.zero_pad(x)\n",
    "        x = self.separable_1(x)\n",
    "        if self.zero_pad:\n",
    "            x = x[:, :, 1:, 1:].contiguous()\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReluConvBn(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(ReluConvBn, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FactorizedReduction(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FactorizedReduction, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential(OrderedDict([\n",
    "            ('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False)),\n",
    "            ('conv', nn.Conv2d(in_channels, out_channels // 2,\n",
    "                               kernel_size=1, bias=False)),\n",
    "        ]))\n",
    "        self.path_2 = nn.Sequential(OrderedDict([\n",
    "            ('pad', nn.ZeroPad2d((0, 1, 0, 1))),\n",
    "            ('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False)),\n",
    "            ('conv', nn.Conv2d(in_channels, out_channels // 2,\n",
    "                               kernel_size=1, bias=False)),\n",
    "        ]))\n",
    "        self.final_path_bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x_path1 = self.path_1(x)\n",
    "\n",
    "        x_path2 = self.path_2.pad(x)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "\n",
    "        out = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "        return out\n",
    "\n",
    "\n",
    "class CellBase(nn.Module):\n",
    "\n",
    "    def cell_forward(self, x_left, x_right):\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_comb_iter_2)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_right)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_left)\n",
    "        if self.comb_iter_4_right:\n",
    "            x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        else:\n",
    "            x_comb_iter_4_right = x_right\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat(\n",
    "            [x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3,\n",
    "             x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class CellStem0(CellBase):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right,\n",
    "                 out_channels_right):\n",
    "        super(CellStem0, self).__init__()\n",
    "        self.conv_1x1 = ReluConvBn(in_channels_right, out_channels_right,\n",
    "                                   kernel_size=1)\n",
    "        self.comb_iter_0_left = BranchSeparables(in_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=5, stride=2,\n",
    "                                                 stem_cell=True)\n",
    "        self.comb_iter_0_right = nn.Sequential(OrderedDict([\n",
    "            ('max_pool', MaxPool(3, stride=2)),\n",
    "            ('conv', nn.Conv2d(in_channels_left, out_channels_left,\n",
    "                               kernel_size=1, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_channels_left, eps=0.001)),\n",
    "        ]))\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=7, stride=2)\n",
    "        self.comb_iter_1_right = MaxPool(3, stride=2)\n",
    "        self.comb_iter_2_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=5, stride=2)\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right,\n",
    "                                                  out_channels_right,\n",
    "                                                  kernel_size=3, stride=2)\n",
    "        self.comb_iter_3_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3)\n",
    "        self.comb_iter_3_right = MaxPool(3, stride=2)\n",
    "        self.comb_iter_4_left = BranchSeparables(in_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 stem_cell=True)\n",
    "        self.comb_iter_4_right = ReluConvBn(out_channels_right,\n",
    "                                            out_channels_right,\n",
    "                                            kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x_left):\n",
    "        x_right = self.conv_1x1(x_left)\n",
    "        x_out = self.cell_forward(x_left, x_right)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class Cell(CellBase):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right,\n",
    "                 out_channels_right, is_reduction=False, zero_pad=False,\n",
    "                 match_prev_layer_dimensions=False):\n",
    "        super(Cell, self).__init__()\n",
    "\n",
    "        # If `is_reduction` is set to `True` stride 2 is used for\n",
    "        # convolutional and pooling layers to reduce the spatial size of\n",
    "        # the output of a cell approximately by a factor of 2.\n",
    "        stride = 2 if is_reduction else 1\n",
    "\n",
    "        # If `match_prev_layer_dimensions` is set to `True`\n",
    "        # `FactorizedReduction` is used to reduce the spatial size\n",
    "        # of the left input of a cell approximately by a factor of 2.\n",
    "        self.match_prev_layer_dimensions = match_prev_layer_dimensions\n",
    "        if match_prev_layer_dimensions:\n",
    "            self.conv_prev_1x1 = FactorizedReduction(in_channels_left,\n",
    "                                                     out_channels_left)\n",
    "        else:\n",
    "            self.conv_prev_1x1 = ReluConvBn(in_channels_left,\n",
    "                                            out_channels_left, kernel_size=1)\n",
    "\n",
    "        self.conv_1x1 = ReluConvBn(in_channels_right, out_channels_right,\n",
    "                                   kernel_size=1)\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=5, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_0_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=7, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_1_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_2_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=5, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right,\n",
    "                                                  out_channels_right,\n",
    "                                                  kernel_size=3, stride=stride,\n",
    "                                                  zero_pad=zero_pad)\n",
    "        self.comb_iter_3_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3)\n",
    "        self.comb_iter_3_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=3, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        if is_reduction:\n",
    "            self.comb_iter_4_right = ReluConvBn(out_channels_right,\n",
    "                                                out_channels_right,\n",
    "                                                kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.comb_iter_4_right = None\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x_left = self.conv_prev_1x1(x_left)\n",
    "        x_right = self.conv_1x1(x_right)\n",
    "        x_out = self.cell_forward(x_left, x_right)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class PNASNet5Large(nn.Module):\n",
    "    def __init__(self, num_classes=1001):\n",
    "        super(PNASNet5Large, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv_0 = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(3, 96, kernel_size=3, stride=2, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(96, eps=0.001))\n",
    "        ]))\n",
    "        self.cell_stem_0 = CellStem0(in_channels_left=96, out_channels_left=54,\n",
    "                                     in_channels_right=96,\n",
    "                                     out_channels_right=54)\n",
    "        self.cell_stem_1 = Cell(in_channels_left=96, out_channels_left=108,\n",
    "                                in_channels_right=270, out_channels_right=108,\n",
    "                                match_prev_layer_dimensions=True,\n",
    "                                is_reduction=True)\n",
    "        self.cell_0 = Cell(in_channels_left=270, out_channels_left=216,\n",
    "                           in_channels_right=540, out_channels_right=216,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_1 = Cell(in_channels_left=540, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_2 = Cell(in_channels_left=1080, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_3 = Cell(in_channels_left=1080, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_4 = Cell(in_channels_left=1080, out_channels_left=432,\n",
    "                           in_channels_right=1080, out_channels_right=432,\n",
    "                           is_reduction=True, zero_pad=True)\n",
    "        self.cell_5 = Cell(in_channels_left=1080, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_6 = Cell(in_channels_left=2160, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432)\n",
    "        self.cell_7 = Cell(in_channels_left=2160, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432)\n",
    "        self.cell_8 = Cell(in_channels_left=2160, out_channels_left=864,\n",
    "                           in_channels_right=2160, out_channels_right=864,\n",
    "                           is_reduction=True)\n",
    "        self.cell_9 = Cell(in_channels_left=2160, out_channels_left=864,\n",
    "                           in_channels_right=4320, out_channels_right=864,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_10 = Cell(in_channels_left=4320, out_channels_left=864,\n",
    "                            in_channels_right=4320, out_channels_right=864)\n",
    "        self.cell_11 = Cell(in_channels_left=4320, out_channels_left=864,\n",
    "                            in_channels_right=4320, out_channels_right=864)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avg_pool = nn.AvgPool2d(11, stride=1, padding=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.last_linear = nn.Linear(4320, num_classes)\n",
    "\n",
    "    def features(self, x):\n",
    "        x_conv_0 = self.conv_0(x)\n",
    "        x_stem_0 = self.cell_stem_0(x_conv_0)\n",
    "        x_stem_1 = self.cell_stem_1(x_conv_0, x_stem_0)\n",
    "        x_cell_0 = self.cell_0(x_stem_0, x_stem_1)\n",
    "        x_cell_1 = self.cell_1(x_stem_1, x_cell_0)\n",
    "        x_cell_2 = self.cell_2(x_cell_0, x_cell_1)\n",
    "        x_cell_3 = self.cell_3(x_cell_1, x_cell_2)\n",
    "        x_cell_4 = self.cell_4(x_cell_2, x_cell_3)\n",
    "        x_cell_5 = self.cell_5(x_cell_3, x_cell_4)\n",
    "        x_cell_6 = self.cell_6(x_cell_4, x_cell_5)\n",
    "        x_cell_7 = self.cell_7(x_cell_5, x_cell_6)\n",
    "        x_cell_8 = self.cell_8(x_cell_6, x_cell_7)\n",
    "        x_cell_9 = self.cell_9(x_cell_7, x_cell_8)\n",
    "        x_cell_10 = self.cell_10(x_cell_8, x_cell_9)\n",
    "        x_cell_11 = self.cell_11(x_cell_9, x_cell_10)\n",
    "        return x_cell_11\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def pnasnet5large(num_classes=2):\n",
    "    r\"\"\"PNASNet-5 model architecture from the\n",
    "    `\"Progressive Neural Architecture Search\"\n",
    "    <https://arxiv.org/abs/1712.00559>`_ paper.\n",
    "    \"\"\"\n",
    "    model = PNASNet5Large(num_classes=num_classes)\n",
    "    return model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pnasnet5large(num_classes=2)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Loss Function and Optimizer\n",
    "I went with Cross-Entropy Loss. __Cross-entropy loss__, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. Hence, predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0.\n",
    "    $$\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
    "                   = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)$$\n",
    "                   \n",
    "I opted with good old __Stochastic Gradient Descent__. Nuff said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optimizer = torch.optim.SGD([\n",
    "    {'params': list(model.parameters())[:-1], 'lr': 1e-3, 'momentum': 0.9, 'weight_decay': 1e-3},\n",
    "    {'params': list(model.parameters())[-1], 'lr': 5e-5, 'momentum': 0.9, 'weight_decay': 1e-5}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Train\n",
    "This is where stripes are earned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 1\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "training_vis = []\n",
    "valid_vis = []\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    training_vis.append(train_loss)\n",
    "    valid_vis.append(valid_loss)\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('\\nValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'PNASNET_gan-detector_test.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "I included here the ability to load a model from previous training runs. Uncomment/Modify what you need to and go HAM. In this case, load the model, the optimizer and the criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load('PNASNET_gan-detector_after96.pt'))\n",
    "# torch.save(model.state_dict(), 'InceptionResnet_gan-detector_95.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Evaluation \n",
    "Earlier we loaded in our test data under the name `test_loader`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "#     print(target)\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "#     print(output)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "#     print(pred)\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(2):\n",
    "#         print(i)\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Performance\n",
    "\n",
    "Most likely, we will want to see how our model performed throughout each epoch. In this plot, we are visualizing training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epoch), training_vis)\n",
    "plt.scatter(range(epoch), training_vis)\n",
    "plt.scatter(range(epoch), valid_vis)\n",
    "plt.plot(range(epoch), valid_vis)\n",
    "# plt.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save the Training and Validation Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('PNASNET.txt', np.array([training_vis, valid_vis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Misclassified\n",
    "\n",
    "Similarly, we will want to see which types of images it correctly classified. In our case, we plot a randomly sampled batch of our test set and place the correct label in parentheses, and the predicted without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds = torch.max(output, 1)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()\n",
    "print(images.shape)\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.swapaxes((images[idx]),axis1=0, axis2=2))\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if classes[preds[idx]]==classes[labels[idx]] else \"red\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Sanity Check Visualization\n",
    "\n",
    "Here, we plot the `RGB` channels of the image, but with a twist. We plot the corresponding RGB value inside the color. Super cool sanity check and overall visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['red channel', 'green channel', 'blue channel']\n",
    "\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    img = rgb_img[idx]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(channels[idx])\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', size=8,\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
